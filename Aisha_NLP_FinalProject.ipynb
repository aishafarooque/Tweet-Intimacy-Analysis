{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishafarooque/Tweet-Intimacy-Analysis/blob/main/Aisha_NLP_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtL71rUgcQBu"
      },
      "source": [
        "# Multilingual Tweet Intimacy Analysis\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Dataset created by: Jiaxin Pei, Francesco Barbieri, Vítor Silva, Maarten Bos, Yozen Liu, Leonardo Neves, David Jurgens\n",
        "\n",
        "The goal of this project is to train machine learning (ML) models to recognize \"intimacy\" in text communications. The authors of this paper define intimacy as \"closeness and interdependence, self-disclosure, and warmth or affection” expressed in the language used to communicate.\n",
        "\n",
        "We have used two datasets, Reddit questions and Multilingual tweets, in this notebook. They have both been compiled by Pei et al. and are used to study if knowledge about intimacy levels of text communication can be transferred easily from tweets to questions or vice versa. \n",
        "\n",
        "(Aisha) leaving these sections here (out-of-order and brainstormed) to help us write the report. \n",
        "\n",
        "## Related Work\n",
        "(Aisha) Fill in any related work if applicable. This should probably go in the report.\n",
        "\n",
        "Leaving some links to clean and well-written notebooks we can use as references:\n",
        "* https://github.com/nlptown/nlp-notebooks/blob/master/An%20Introduction%20to%20Word%20Embeddings.ipynb \n",
        "* https://github.com/nlptown/nlp-notebooks/blob/master/Discovering%20and%20Visualizing%20Topics%20in%20Texts%20with%20LDA.ipynb \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7y6c09Dof8j"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBMquumpocGx",
        "outputId": "1a01613a-7ef1-475b-e1e7-a5ceb3126345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 25.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade pip\n",
        "! pip install transformers\n",
        "! pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpHFYYTKKuLP"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0oPGqR4Hq_r"
      },
      "source": [
        "Downloading the Twitter dataset from the Multilingual Tweet Intimacy Analysis Codalab competition ([source](https://codalab.lisn.upsaclay.fr/competitions/7096#learn_the_details-overview))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5UYoLaAaF5E",
        "outputId": "58fa5ab0-c514-4dd9-e4c9-96ec962eeaa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-30 23:54:50--  https://raw.githubusercontent.com/aishafarooque/Tweet-Intimacy-Analysis/main/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813066 (794K) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>] 794.01K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2022-11-30 23:54:51 (117 MB/s) - ‘train.csv’ saved [813066/813066]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Remove Twitter's train.csv if it already exists\n",
        "! rm -rf train.csv\n",
        "\n",
        "# Download Twitter's training data\n",
        "! wget https://raw.githubusercontent.com/aishafarooque/Tweet-Intimacy-Analysis/main/train.csv\n",
        "\n",
        "# Rename train.csv -> twitter_train.csv for more clarity\n",
        "! mv train.csv twitter_train.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDC_-zTmH4-X"
      },
      "source": [
        "Downloading the Reddit dataset from the author's GitHub repository: Quantifying-Intimacy-in-Language\n",
        " ([source](https://github.com/Jiaxin-Pei/Quantifying-Intimacy-in-Language/blob/main/data/annotated_question_intimacy_data.zip))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWDkJH8tH_tD",
        "outputId": "e4b76f04-87c5-4814-f9ac-aa10e59ec479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-30 23:54:51--  https://raw.githubusercontent.com/Jiaxin%2DPei/Quantifying%2DIntimacy%2Din%2DLanguage/main/data/annotated_question_intimacy_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94741 (93K) [application/zip]\n",
            "Saving to: ‘annotated_question_intimacy_data.zip’\n",
            "\n",
            "annotated_question_ 100%[===================>]  92.52K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-11-30 23:54:52 (48.6 MB/s) - ‘annotated_question_intimacy_data.zip’ saved [94741/94741]\n",
            "\n",
            "Archive:  /content/annotated_question_intimacy_data.zip\n",
            "   creating: annotated_question_intimacy_data/\n",
            "  inflating: annotated_question_intimacy_data/final_train.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/annotated_question_intimacy_data/\n",
            "  inflating: __MACOSX/annotated_question_intimacy_data/._final_train.txt  \n",
            "  inflating: annotated_question_intimacy_data/final_val.txt  \n",
            "  inflating: __MACOSX/annotated_question_intimacy_data/._final_val.txt  \n",
            "  inflating: annotated_question_intimacy_data/final_test.txt  \n",
            "  inflating: __MACOSX/annotated_question_intimacy_data/._final_test.txt  \n",
            "  inflating: annotated_question_intimacy_data/final_external.txt  \n"
          ]
        }
      ],
      "source": [
        "# Sanitze working directory\n",
        "! rm -rf /content/__MACOSX\n",
        "! rm -rf /content/annotated_question_intimacy_data\n",
        "\n",
        "# Removing the .zip file if it already exists.\n",
        "! rm -rf annotated_question_intimacy_data.zip\n",
        "\n",
        "# Download the dataset from the author's GitHub repository.\n",
        "! wget https://raw.githubusercontent.com/Jiaxin%2DPei/Quantifying%2DIntimacy%2Din%2DLanguage/main/data/annotated_question_intimacy_data.zip\n",
        "\n",
        "# Unzip the file. \n",
        "! unzip /content/annotated_question_intimacy_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opsn06XGc9z5"
      },
      "source": [
        "## Data fact study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0p2FnOS2XK"
      },
      "source": [
        "### Twitter Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0UHCkZzMSso"
      },
      "source": [
        "The Twitter dataset has a total of 9491 rows and 3 columns which are:\n",
        "* Tweet - Textual content of the tweet\n",
        "* Intimacy Label - Intimacy score of the tweet, ranging from 1 (least intimate) to 5 (most intimate).\n",
        "* Language - The language the tweet is written in. There are six languages in this datasset:  English, Spanish, Italian, Portuguese, French, and Chinese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKCYp1TGbX7i",
        "outputId": "6323c4be-90cd-4e7d-ff38-cdb107ec76d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 9491 \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9491 entries, 0 to 9490\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   document  9491 non-null   object \n",
            " 1   label     9491 non-null   float64\n",
            " 2   language  9491 non-null   object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 222.6+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "twitter_df_train = pd.read_csv('/content/twitter_train.csv', on_bad_lines='skip')\n",
        "twitter_df_train = twitter_df_train.rename(columns={'text': 'document', 'label': 'label'})\n",
        "\n",
        "print(\"Dataset size:\", len(twitter_df_train), '\\n')\n",
        "twitter_df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Sh0Jytk4MNHZ",
        "outputId": "e6d35b58-27f6-442c-f956-1103e566391c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               document  label language\n",
              "596               @user I've tried it. It's good. 😎👍🤟👋🫡    2.5  English\n",
              "8104    这样的剧情真是爱死了😏 有想体验主角一样剧情的小伙伴么🤭 QQ:3123657769 http    2.6  Chinese\n",
              "5973  Giù le mani dai bambini #Bibbiano #bibbianoeno...    1.2  Italian\n",
              "8232            給最近突然爆量追蹤我的中國朋友： #去你的中國武漢肺炎 好了你們可以退追蹤了。    2.0  Chinese\n",
              "6418                          Un peu de couleur... http    1.5   French"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f0f31ad-b70b-4d38-8736-1c8296b82fce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>@user I've tried it. It's good. 😎👍🤟👋🫡</td>\n",
              "      <td>2.5</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8104</th>\n",
              "      <td>这样的剧情真是爱死了😏 有想体验主角一样剧情的小伙伴么🤭 QQ:3123657769 http</td>\n",
              "      <td>2.6</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>Giù le mani dai bambini #Bibbiano #bibbianoeno...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>Italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8232</th>\n",
              "      <td>給最近突然爆量追蹤我的中國朋友： #去你的中國武漢肺炎 好了你們可以退追蹤了。</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>Un peu de couleur... http</td>\n",
              "      <td>1.5</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f0f31ad-b70b-4d38-8736-1c8296b82fce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f0f31ad-b70b-4d38-8736-1c8296b82fce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f0f31ad-b70b-4d38-8736-1c8296b82fce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "twitter_df_train.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhpoAUc_P1y3"
      },
      "source": [
        "Looking at the distribution of tweets in the dataset we can see that, approximately, there are equal number of tweets across all six languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aJQ8hf5OP1Hs",
        "outputId": "014adbe3-cb97-4390-b3bc-a7c9bdd9845d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f99356c3430>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_23651_row0_col1, #T_23651_row1_col1 {\n",
              "  background-color: #023858;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_23651_row2_col1 {\n",
              "  background-color: #034871;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_23651_row3_col1 {\n",
              "  background-color: #04598c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_23651_row4_col1 {\n",
              "  background-color: #045c90;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_23651_row5_col1 {\n",
              "  background-color: #fff7fb;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_23651_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >language</th>\n",
              "      <th class=\"col_heading level0 col1\" >document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_23651_row0_col0\" class=\"data row0 col0\" >Chinese</td>\n",
              "      <td id=\"T_23651_row0_col1\" class=\"data row0 col1\" >1596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
              "      <td id=\"T_23651_row1_col0\" class=\"data row1 col0\" >Portuguese</td>\n",
              "      <td id=\"T_23651_row1_col1\" class=\"data row1 col1\" >1596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row2\" class=\"row_heading level0 row2\" >5</th>\n",
              "      <td id=\"T_23651_row2_col0\" class=\"data row2 col0\" >Spanish</td>\n",
              "      <td id=\"T_23651_row2_col1\" class=\"data row2 col1\" >1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
              "      <td id=\"T_23651_row3_col0\" class=\"data row3 col0\" >French</td>\n",
              "      <td id=\"T_23651_row3_col1\" class=\"data row3 col1\" >1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row4\" class=\"row_heading level0 row4\" >1</th>\n",
              "      <td id=\"T_23651_row4_col0\" class=\"data row4 col0\" >English</td>\n",
              "      <td id=\"T_23651_row4_col1\" class=\"data row4 col1\" >1587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_23651_level0_row5\" class=\"row_heading level0 row5\" >3</th>\n",
              "      <td id=\"T_23651_row5_col0\" class=\"data row5 col0\" >Italian</td>\n",
              "      <td id=\"T_23651_row5_col1\" class=\"data row5 col1\" >1532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tweet_distribution = twitter_df_train.groupby('language').count()['document']\\\n",
        "                      .reset_index().sort_values(by='document',ascending=False)\n",
        "tweet_distribution.style.background_gradient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ILpCzzegdmC"
      },
      "source": [
        "### Reddit Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPYMYQV6kWDA"
      },
      "source": [
        "The Reddit dataset has a total of 1797 rows and 2 columns which are:\n",
        "* Question - Textual content of the Reddit question in English\n",
        "* Intimacy Score - Intimacy score of the tweet, ranging from -1 (least intimate) to 1 (most intimate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq7g0U-gjApY",
        "outputId": "e75c13db-f883-4764-c24c-01f221449516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1797 \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1797 entries, 0 to 1796\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   document  1797 non-null   object \n",
            " 1   label     1797 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 28.2+ KB\n"
          ]
        }
      ],
      "source": [
        "reddit_df_train = pd.read_csv('/content/annotated_question_intimacy_data/final_train.txt', \n",
        "                              sep='\\t', header=None, names=['document', 'label'])\n",
        "\n",
        "print(\"Dataset size:\", len(reddit_df_train), '\\n')\n",
        "reddit_df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EjEPL_CmkuNt",
        "outputId": "c6e51fc3-d609-4baa-8bdf-7ec7e9091e01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            document     label\n",
              "0  What are the most mediocre animals in the anim... -0.338354\n",
              "1  What's the difference between an allergic reac...  0.035508\n",
              "2  What is your favorite subreddit that not every...  0.047134\n",
              "3  What's the most disgusting meal you've ever ea...  0.247764\n",
              "4           Whats one question you hate being asked?  0.516920"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-799a2c66-f250-4896-9ce1-6b679408fc80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the most mediocre animals in the anim...</td>\n",
              "      <td>-0.338354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What's the difference between an allergic reac...</td>\n",
              "      <td>0.035508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is your favorite subreddit that not every...</td>\n",
              "      <td>0.047134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's the most disgusting meal you've ever ea...</td>\n",
              "      <td>0.247764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Whats one question you hate being asked?</td>\n",
              "      <td>0.516920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-799a2c66-f250-4896-9ce1-6b679408fc80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-799a2c66-f250-4896-9ce1-6b679408fc80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-799a2c66-f250-4896-9ce1-6b679408fc80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reddit_df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkGy0Ypl8I-y"
      },
      "source": [
        "#### Performing Linear Mapping on the Reddit Dataset\n",
        "\n",
        "Since the ```intimacy_scores``` in the Reddit dataset is on a range from -1 to 1, we will linearly map them from 1 to 5. The linear mapping with maintain a constant ratio between the points. \n",
        "\n",
        "We will perform the following:\n",
        "- A scaling operation to adjust the ranges to the same size, and\n",
        "- An offset operation to adjust range alignment. \n",
        "\n",
        "Source: http://learnwebgl.brown37.net/08_projections/projections_mapping.html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gsOU_Stk9bSn",
        "outputId": "3cd66f10-41c7-4752-a57b-3e6aecca86f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            document  label\n",
              "0  What are the most mediocre animals in the anim...    2.3\n",
              "1  What's the difference between an allergic reac...    3.1\n",
              "2  What is your favorite subreddit that not every...    3.1\n",
              "3  What's the most disgusting meal you've ever ea...    3.5\n",
              "4           Whats one question you hate being asked?    4.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0104cce3-125b-4529-9ea0-b46e54d8c14e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the most mediocre animals in the anim...</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What's the difference between an allergic reac...</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is your favorite subreddit that not every...</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's the most disgusting meal you've ever ea...</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Whats one question you hate being asked?</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0104cce3-125b-4529-9ea0-b46e54d8c14e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0104cce3-125b-4529-9ea0-b46e54d8c14e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0104cce3-125b-4529-9ea0-b46e54d8c14e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "A, B, C, D = -1, 1, 1, 5\n",
        "scale = (D-C)/(B-A)\n",
        "offset = -A*(D-C)/(B-A) + C\n",
        "\n",
        "for index, row in reddit_df_train.iterrows():\n",
        "  iScore = row['label']\n",
        "\n",
        "  # If the cell is re-run without clearing local variables, we'll\n",
        "  # double convert the values between the 1-5 range resulting in values between\n",
        "  # 5-10. This condition makes sure original scores from Reddit are not already\n",
        "  #  greater than 1. \n",
        "  if iScore > 1:\n",
        "    break\n",
        "\n",
        "  q = iScore * scale + offset\n",
        "  reddit_df_train.at[index, 'label'] = round(q, 1)\n",
        "  \n",
        "reddit_df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18zWc2ytm1y"
      },
      "source": [
        "## Define the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJgSdTICDnVY",
        "outputId": "747acaef-44fd-415a-b0d4-b4c2b77c2ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=974ccdd4457c30aa114805284efd0c36af8035d2f6b353e172dd2ce2e7ed3587\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/30/9b/6b670dac34775f2b7cc4e9b172202e81fbb4f9cdb103c1ca66\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from bertviz) (0.1.97)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from bertviz) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from bertviz) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bertviz) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.20-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.8/dist-packages (from bertviz) (1.12.1+cu113)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.8/dist-packages (from bertviz) (4.24.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0->bertviz) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.0->bertviz) (1.21.6)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.20\n",
            "  Downloading botocore-1.29.20-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bertviz) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bertviz) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bertviz) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bertviz) (2.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.20->boto3->bertviz) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.20->boto3->bertviz) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, bertviz\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed bertviz-1.4.0 boto3-1.26.20 botocore-1.29.20 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.25.11\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, multiprocess, responses, datasets\n",
            "Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 xxhash-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece\n",
        "! pip install transformers\n",
        "! pip install seqeval\n",
        "! pip install bertviz\n",
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pA_etpKruiSs"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import transformers\n",
        "\n",
        "# set up verbosity of libraries\n",
        "datasets.utils.logging.set_verbosity_error()\n",
        "transformers.utils.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AIOjqyZNoHzb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Set up device. Recommend to use GPU to accelerate training\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1Vdt36Ofu1Oq"
      },
      "outputs": [],
      "source": [
        "PRETRAINED_MODEL_NAME = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "IGNORE_INDEX = -100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "6d3c31c9f8014562b676e7c34beca0f4",
            "da1cf1da675f423dad53ba11498fcc32",
            "db80e30bafbc440f8da11f77aac83e49",
            "039fe685a0df42329212f8760eeeefa1",
            "9760c8d4f82a49ccad745e175979be03",
            "a3d51f91a9c04663a8f88bb17ffaf8ba",
            "5ba1f18634bd4f49bf697edbb342f076",
            "6d1da948ec124e6b84904d9ad9b6f5ab",
            "16ef0eaa75db4713a0f89b2e5432bf01",
            "de58883396f14d13a5c64c7f8e84c507",
            "15acb395715b496cab8f5176dfeb82d4",
            "a2e0c3ba4bd3496c8e4decb8c18407cb",
            "ebe47b4f2bf4438fb45da13a8df4d0ff",
            "f53faea6f2ec45029ad932611a186493",
            "4424baea97324ee59fb3e0dbf40d3926",
            "8aa67ed2f61b4fc2816f77f11ba00d72",
            "c87dee169afd45f79632468bc2c16b62",
            "e17173aad7b643fa8ece2476beb5214e",
            "d8ca877f45c140918b0e72ec43248898",
            "0c83c07755e64dcfa35da38c9ee0caab",
            "8bd3cbd5a83749b2bd444a822879e466",
            "c9116ad54d84406fa10a16ca9086704a",
            "57aa4cd09b1c45b1827612a3f92b1716",
            "4a7317833504444298d2d2be746d1855",
            "cdcc8425ced5466d87242f400998dfd9",
            "86145b497b2a4f16b717f9f83797a9b6",
            "53d7bdf52bd64682811b42ad048b728f",
            "b9ec39f35ee248f8b37166ef9766aab5",
            "fdb08d4f8c414dc7b6d460f48669c246",
            "8ee744dc5725493e98ee92ed1e8474a1",
            "d4d3855b90074cf78ae20397620da34e",
            "a8f21d425e274ddeb635e144df3fddea",
            "161c6f477813474a8e2c1a71c3d709b7"
          ]
        },
        "id": "KYDyN1-Lurnf",
        "outputId": "7a60601f-c60d-4082-99c0-06c60594a3eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/841 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d3c31c9f8014562b676e7c34beca0f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2e0c3ba4bd3496c8e4decb8c18407cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57aa4cd09b1c45b1827612a3f92b1716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='cardiffnlp/twitter-xlm-roberta-base-sentiment', vocab_size=250002, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psgQJz7bdFGB"
      },
      "source": [
        "## Data split\n",
        "\n",
        "The data will be split into training and testing datasets.\n",
        "The training dataset will be 80% of the data from the Reddit and Twitter datasets. This dataset will be used to fine tune the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mNynH9HWQxIH"
      },
      "outputs": [],
      "source": [
        "# Declare constants for commonly used strings\n",
        "TWEET = 'tweet'\n",
        "REDDIT = 'reddit'\n",
        "TRAIN = 'train'\n",
        "TEST = 'test'\n",
        "COMBINED = 'combined'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eo1bIjE8grhU"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, train_size, test_size):\n",
        "  X = dataset['document']\n",
        "  y = dataset['label']\n",
        "\n",
        "  # Bin size = 1.0\n",
        "  bins = np.linspace(start=1.0, stop=5.0, num=5)\n",
        "\n",
        "  binned_y = np.digitize(y, bins)\n",
        "  X_train, X_rem, y_train, y_rem = train_test_split(X, y, \n",
        "                                                    stratify=binned_y, \n",
        "                                                    train_size=train_size)\n",
        "\n",
        "  binned_y_rem = np.digitize(y_rem, bins)\n",
        "  X_test, X_valid, y_test, y_valid = train_test_split(X_rem, y_rem, \n",
        "                                                      stratify=binned_y_rem, \n",
        "                                                      test_size=test_size)\n",
        "  \n",
        "  print (f'X_train: {X_train.shape}, X_rem: {X_rem.shape}, y_train: {y_train.shape}, y_rem: {y_rem.shape}')\n",
        "  print (f'X_test: {X_test.shape}, X_valid: {X_valid.shape}, y_test: {y_test.shape}, y_valid: {y_valid.shape}')\n",
        "  \n",
        "  return {'train': {'X': X_train, 'y': y_train},\n",
        "          'test': {'X': X_test, 'y': y_test},\n",
        "          'valid': {'X': X_valid, 'y': y_valid}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NVRW-Cy1kI4q"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Combines collections from the same split of two datasets into one collection to use as a split of the combined dataset.\n",
        "\"\"\"\n",
        "def combine_sets(a, b):\n",
        "  # Simple concatenation. Is there another way we want to try combining them\n",
        "  #  (e.g. zipping/mixing them together?)\n",
        "  return [a_item for a_item in a] + [b_item for b_item in b]\n",
        "  \"\"\"\n",
        "  Note(Orion:) this doesn't work because the documents are not simple lists!\n",
        "  \"\"\"\n",
        "\n",
        "def combine_splits(a_split, b_split):\n",
        "  return {split_name: {variable: combine_sets(a_split[split_name][variable], b_split[split_name][variable]) \n",
        "                       for variable in a_split[split_name]} \n",
        "          for split_name in a_split}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJk6fqGMIWvm",
        "outputId": "a9046293-0c06-4020-ffc8-214c4f2e10d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (7592,), X_rem: (1899,), y_train: (7592,), y_rem: (1899,)\n",
            "X_test: (949,), X_valid: (950,), y_test: (949,), y_valid: (950,)\n",
            "X_train: (1437,), X_rem: (360,), y_train: (1437,), y_rem: (360,)\n",
            "X_test: (180,), X_valid: (180,), y_test: (180,), y_valid: (180,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Pull x and y values from dataframe\n",
        "datasets = {'tweet': twitter_df_train, 'reddit': reddit_df_train}\n",
        "\n",
        "# Define train:test:valid split ratios\n",
        "split_ratios = {'tweet': {'train_total_ratio': 0.8,\n",
        "                          'test_rem_ratio': 0.5},\n",
        "                \n",
        "                # Train:test:valid ratio of 8:1:1 for Reddit dataset\n",
        "                'reddit': {'train_total_ratio': 0.8,\n",
        "                           'test_rem_ratio': 0.5}}\n",
        "\n",
        "# Split individual tweet/reddit datasets\n",
        "split_datasets = {key: split_dataset(datasets[key], \n",
        "                                     split_ratios[key]['train_total_ratio'],\n",
        "                                     split_ratios[key]['test_rem_ratio'])\n",
        "                  for key in datasets}\n",
        "\n",
        "# Create and split combined dataset\n",
        "split_datasets['combined'] = combine_splits(split_datasets['tweet'], \n",
        "                                            split_datasets['reddit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ka5_qlfBr5W",
        "outputId": "b365a0ff-f44a-4d7c-ddc3-9fc633b856a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet', 'reddit', 'combined'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "split_datasets.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ukVb0RB0Tf",
        "outputId": "50ef3091-0a04-49bb-8b03-064498514d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in tweet are dict_keys(['train', 'test', 'valid'])\n",
            "Keys in reddit are dict_keys(['train', 'test', 'valid'])\n",
            "Keys in combined are dict_keys(['train', 'test', 'valid'])\n"
          ]
        }
      ],
      "source": [
        "print (f'Keys in {TWEET} are {split_datasets[TWEET].keys()}')\n",
        "print (f'Keys in {REDDIT} are {split_datasets[REDDIT].keys()}')\n",
        "print (f'Keys in {COMBINED} are {split_datasets[COMBINED].keys()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "O2T_2R1dCS0J"
      },
      "outputs": [],
      "source": [
        "# Ensure the features were correctly combines\n",
        "features_in_twitter = len(split_datasets[TWEET][TRAIN]['X'])\n",
        "features_in_reddit = len(split_datasets[REDDIT][TRAIN]['X'])\n",
        "features_in_combined = len(split_datasets[COMBINED][TRAIN]['X'])\n",
        "\n",
        "assert features_in_combined == (features_in_twitter + features_in_reddit), f'Features do not match'\n",
        "\n",
        "# Ensure the labels were correctly combined\n",
        "labels_in_twitter = len(split_datasets[TWEET][TRAIN]['y'])\n",
        "labels_in_reddit = len(split_datasets[REDDIT][TRAIN]['y'])\n",
        "labels_in_combined = len(split_datasets[COMBINED][TRAIN]['y'])\n",
        "\n",
        "assert labels_in_combined == (labels_in_twitter + labels_in_reddit), f'Labels do not match'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jjesZVYGUcp"
      },
      "source": [
        "After splitting the dataset, we will be left with the following structure:\n",
        "\n",
        "```\n",
        "split_datasets\n",
        "├── tweet\n",
        "│   ├── train\n",
        "│   │   ├── X\n",
        "│   │   └── y\n",
        "│   ├── test\n",
        "│   └── valid\n",
        "├── reddit\n",
        "│   ├── train\n",
        "│   ├── test\n",
        "│   └── valid\n",
        "└── combined\n",
        "    ├── train\n",
        "    ├── test\n",
        "    └── valid\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG3BOzbvFVZi"
      },
      "source": [
        "## Research regarding data and data split\n",
        "\n",
        "Pei and Jurgens (2020) conducted analyses for an issue in pre-processing, where they were only able to do it for 1,000 tweets. They found that the distribution of the final annotated intimacy scores are not changed much while the fine-tuned XLM-T only achieved a Pearson’s r of 0.43 on the random sample, suggesting that the model trained on Reddit questions may not be reliable enough to detect intimacy in tweets. A potential goal of ours is too improve upon this making the model reliable for even reddit questions.\n",
        "\n",
        "(Liu et al., 2019) include two variants: one which is fine-tuned on 3M unannotated questions on a masked language modeling task, and a second which uses the default parameters in RoBERTa. Training uses only the 2,247 annotated Reddit questions, split 8:1:1 into training, validation, and test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8UBMZXFiBkl"
      },
      "source": [
        "## Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qhe6gW2vQKx"
      },
      "source": [
        "Before sending the data to the model, we will preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VQjKXJnojzV",
        "outputId": "faae2b36-599d-401c-bc09-fff66233d460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XVIQKO4yUlA"
      },
      "source": [
        "### Define the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYVVj8TCkdhE"
      },
      "source": [
        "We will have identifiers for each word in a language produced by tokenization. During this process, chunks of words, such as a sentence or a phrase, are broken down into smaller units. Each unit is called a token which could be words, numbers, or punctuation marks. \n",
        "\n",
        "Any word not in our dictionary will be replaced with the `unknown` token. \n",
        "\n",
        "Reference:\n",
        "- [Tokenizer - huggingface.co](https://huggingface.co/docs/transformers/main_classes/tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ntGh4lzSiT1V"
      },
      "outputs": [],
      "source": [
        "def tokenize_catch_unknown(word, tokenizer, vocab):\n",
        "  \"\"\"\n",
        "  Description: Tokenizes a word if it is known, but catches unknown words and replaces it with unknown tokens.\n",
        "  \n",
        "  \"\"\"\n",
        "  if vocab.get(word):\n",
        "    return tokenizer.tokenize(word)\n",
        "  else:\n",
        "    return [tokenizer.unk_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_ve1a_GBqSDW"
      },
      "outputs": [],
      "source": [
        "def prepare_document_encoding(document, tokenizer, vocab):\n",
        "  \"\"\"\n",
        "  Description: Converts one document (a tweet or other text) into tokens in the model's vocabulary.\n",
        "  Returns a dictionary containing the tokens as text, the numerical ids of the tokens, and the score label for the document (already numerical here)\n",
        "\n",
        "  \"\"\"\n",
        "  tokenized = [tokenizer.cls_token] + [token for word in document for token in tokenize_catch_unknown(word, tokenizer, vocab)]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(token) for token in tokenized]\n",
        "\n",
        "  return {\"tokenized\": tokenized, \n",
        "          \"input_ids\": input_ids}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QxXyCQs_pA8B"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data, tokenizer, vocab):\n",
        "  \"\"\"\n",
        "  Description: Converts the documents in the data into tokens in the model's vocabulary.\n",
        "\n",
        "  \"\"\"\n",
        "  for split in data:\n",
        "    data[split]['tokenized'] = []\n",
        "    data[split]['input_ids'] = []\n",
        "    data[split]['labels'] = []\n",
        "\n",
        "    for document, label in zip(data[split]['X'], data[split]['y']):\n",
        "      prepared_document = prepare_document_encoding(document, tokenizer, vocab)\n",
        "\n",
        "      data[split]['tokenized'] += [prepared_document['tokenized']]\n",
        "      data[split]['input_ids'] += [prepared_document['input_ids']]\n",
        "      data[split]['labels'] += [label]\n",
        "\n",
        "  return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0tBXz_-gvv1c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IADataset(Dataset):\n",
        "  def __init__(self, data, pad_token_id):\n",
        "        self.tokenized = data['tokenized']\n",
        "        self.input_ids = data['input_ids']\n",
        "        self.labels = data['labels']\n",
        "\n",
        "        self.pad_token_id = pad_token_id\n",
        "  \n",
        "  def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.labels[index]\n",
        "\n",
        "  # Try without batch collation\n",
        "  def collate_fn(self, batch):\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            This function collates lists of samples into batches. It should be passed as the `collate_fn` argument when creating dataloaders.\n",
        "        Inputs:\n",
        "            - batch (List[Tuple]): a list of tuples. The tuple (Tuple[List]) in the batch is the return value (List[List]) of \n",
        "              `__getitem(self, index)` function. The elements are: 1) a List[int] (input_ids) and 2) a real (label).\n",
        "        Outputs:\n",
        "            - input_dict (Dict[str, torch.LongTensor]): a dictionary containing a mapping between input names and input values. The `input_ids` \n",
        "              (torch.LongTensor of shape (batch_size, sequence_length)) and `labels` (torch.FloatTensor of shape (batch_size, sequence_length)) \n",
        "              in the dictionary are token indexes and label values, respectively.\n",
        "        \"\"\"\n",
        "\n",
        "        # unwrap the batch into every field\n",
        "        input_ids, labels = map(list, zip(*batch))\n",
        "\n",
        "        max_length = max(map(len, input_ids))\n",
        "\n",
        "        padded_input_ids = [i + [self.pad_token_id] * (max_length - len(i)) for i in input_ids]\n",
        "        attention_masks = [[1 for id in i] + [0] * (max_length - len(i)) for i in input_ids]\n",
        "\n",
        "        input_dict = {\n",
        "            'input_ids': torch.tensor(padded_input_ids).long(),\n",
        "            'attention_masks': torch.tensor(attention_masks).long(),\n",
        "            'labels': torch.tensor(labels).to(torch.float64)\n",
        "        }\n",
        "\n",
        "        return input_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TvHaduy9yDyp"
      },
      "outputs": [],
      "source": [
        "def get_ia_splits(data, pad_token_id):\n",
        "  \"\"\"\n",
        "  Description: Creates IADatasets around each split of the dataset.\n",
        "  \"\"\"\n",
        "  ia_splits = {split: IADataset(data[split], pad_token_id)\n",
        "                  for split in data}\n",
        "\n",
        "  return ia_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LB7ox430t3bx"
      },
      "outputs": [],
      "source": [
        "# Convert the documents into sequences of input ids in the model's vocabulary\n",
        "vocab = tokenizer.get_vocab()\n",
        "\n",
        "# prepared_datasets = {key: prepare_data(split_datasets[key], tokenizer, vocab) for key in split_datasets}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_bwoK0Do-_Z",
        "outputId": "062a5104-afb8-4deb-f179-dbe052f714d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet', 'reddit', 'combined'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Saved prepared datasets locally.\n",
        "# with open('objs.pkl', 'wb') as f:\n",
        "#     pickle.dump(prepared_datasets, f)\n",
        "\n",
        "# ! cp /content/objs.pkl /content/drive/Shareddrives/tesrt/nlp_final/objs.pkl\n",
        "\n",
        "\n",
        "# (Aisha) Read the file - because preparing the datasets takes a long time\n",
        "# and my session kept crashing.\n",
        "with open('/content/drive/Shareddrives/tesrt/nlp_final/objs.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
        "    prepared_datasets = pickle.load(f)\n",
        "\n",
        "prepared_datasets.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kW_b35tDED9u"
      },
      "outputs": [],
      "source": [
        "assert len(prepared_datasets[TWEET][TRAIN]['X']) == features_in_twitter, f\"Mismatched sizes, expected {features_in_twitter}, got {len(prepared_datasets[TWEET][TRAIN]['X'])}\"\n",
        "assert len(prepared_datasets[REDDIT][TRAIN]['X']) == features_in_reddit, f\"Mismatched sizes, expected {features_in_reddit}, got {len(prepared_datasets[REDDIT][TRAIN]['X'])}\"\n",
        "assert len(prepared_datasets[COMBINED][TRAIN]['X']) == features_in_combined, f\"Mismatched sizes, expected {features_in_combined}, got {len(prepared_datasets[COMBINED][TRAIN]['X'])}\"\n",
        "\n",
        "assert len(prepared_datasets[TWEET][TRAIN]['y']) == labels_in_twitter, f\"Mismatched sizes, expected {labels_in_twitter}, got {len(prepared_datasets[TWEET][TRAIN]['y'])}\"\n",
        "assert len(prepared_datasets[REDDIT][TRAIN]['y']) == labels_in_reddit, f\"Mismatched sizes, expected {labels_in_reddit}, got {len(prepared_datasets[REDDIT][TRAIN]['y'])}\"\n",
        "assert len(prepared_datasets[COMBINED][TRAIN]['y']) == labels_in_combined, f\"Mismatched sizes, expected {labels_in_combined}, got {len(prepared_datasets[COMBINED][TRAIN]['y'])}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_zb4zynba0N",
        "outputId": "2307cb9b-873f-432e-f609-2f19ccca35fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tweet': {'train': <__main__.IADataset at 0x7f9855d29e20>,\n",
              "  'test': <__main__.IADataset at 0x7f9855d29d30>,\n",
              "  'valid': <__main__.IADataset at 0x7f9855d29d00>},\n",
              " 'reddit': {'train': <__main__.IADataset at 0x7f9855d29c70>,\n",
              "  'test': <__main__.IADataset at 0x7f9855d29b50>,\n",
              "  'valid': <__main__.IADataset at 0x7f9855d29ee0>},\n",
              " 'combined': {'train': <__main__.IADataset at 0x7f9855d29d90>,\n",
              "  'test': <__main__.IADataset at 0x7f9855d29bb0>,\n",
              "  'valid': <__main__.IADataset at 0x7f985f08ef70>}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "ia_datasets = {key: get_ia_splits(prepared_datasets[key], \n",
        "                                    pad_token_id=tokenizer.pad_token_id) \n",
        "               for key in prepared_datasets}\n",
        "ia_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pmai-1BKwC2",
        "outputId": "996c4fac-956c-4474-d712-564c5cdbab4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--TRAIN--\n",
            "IA Dataset Twitter length: 7592\n",
            "IA Dataset Reddit length: 1437\n",
            "IA Dataset combined length: 9029\n",
            "--TEST--\n",
            "IA Dataset Twitter length: 949\n",
            "IA Dataset Reddit length: 180\n",
            "IA Dataset combined length: 1129\n"
          ]
        }
      ],
      "source": [
        "print ('--TRAIN--')\n",
        "print (f'IA Dataset Twitter length: {len(ia_datasets[TWEET][TRAIN].tokenized)}')\n",
        "print (f'IA Dataset Reddit length: {len(ia_datasets[REDDIT][TRAIN].tokenized)}')\n",
        "print (f'IA Dataset combined length: {len(ia_datasets[COMBINED][TRAIN].tokenized)}')\n",
        "\n",
        "print ('--TEST--')\n",
        "print (f'IA Dataset Twitter length: {len(ia_datasets[TWEET][TEST].tokenized)}')\n",
        "print (f'IA Dataset Reddit length: {len(ia_datasets[REDDIT][TEST].tokenized)}')\n",
        "print (f'IA Dataset combined length: {len(ia_datasets[COMBINED][TEST].tokenized)}')\n",
        "\n",
        "assert len(ia_datasets[TWEET][TRAIN].tokenized) == features_in_twitter, f\"Mismatched sizes, expected {features_in_twitter}, got {len(ia_datasets[TWEET][TRAIN].tokenized)}\"\n",
        "assert len(ia_datasets[REDDIT][TRAIN].tokenized) == features_in_reddit, f\"Mismatched sizes, expected {features_in_reddit}, got {len(ia_datasets[REDDIT][TRAIN].tokenized)}\"\n",
        "assert len(ia_datasets[COMBINED][TRAIN].tokenized) == features_in_combined, f\"Mismatched sizes, expected {features_in_combined}, got {len(ia_datasets[COMBINED][TRAIN].tokenized)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbHVI5-LMV7S"
      },
      "source": [
        "The folder structure for `ia_datasets` will be:\n",
        "```\n",
        "ia_datasets\n",
        "├── tweet\n",
        "│   ├── train\n",
        "│   │   ├── tokenized\n",
        "│   │   ├── input_ids\n",
        "│   │   ├── labels\n",
        "│   │   └── pad_token_ids\n",
        "│   ├── test\n",
        "│   └── valid\n",
        "├── reddit\n",
        "└── combined\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc2y6CjmjOkk",
        "outputId": "083db3e2-ec60-45bd-e051-8231016bdd6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Cleanup to save RAM\n",
        "del prepared_datasets\n",
        "del split_datasets\n",
        "del reddit_df_train\n",
        "del twitter_df_train\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGYgcEyZyfBd"
      },
      "source": [
        "### Define the DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKGXEDu2vX4j"
      },
      "source": [
        "Dataloaders are constructs of the PyTorch library which define and control data preprocessing. The data will be fed in batches to the model. This is important because it is inefficient to load the data altogether in memory at once. The size of the data loaded at any given time into memory is controlled by the `batch_size` which is 32 for the training, validation and testing datasets.  \n",
        "\n",
        "Every DataLoader has a Sampler which is used internally to get the indices for each batch. \n",
        "\n",
        "The `SequentialSampler` iterates over the dataset in a sequential order. For example: `[1,2,3]` -> `1,2,3`. Here the `shuffle` parameter is set to `false`.\n",
        "\n",
        "The `RandomSampler` is just like it's sequential counterpart, but with `shuffle=True`.\n",
        "\n",
        "\n",
        "References:\n",
        "- [torch.utils.data — PyTorch 1.13 documentation](https://pytorch.org/docs/stable/data.html)\n",
        "- [SequentialSampler](https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html#SequentialSampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69lZIC8YyeRQ",
        "outputId": "f2205ab6-ecc6-4c5f-9458-befa55187932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tweet': {'train': <torch.utils.data.dataloader.DataLoader at 0x7f985360bfd0>,\n",
              "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f985360be20>,\n",
              "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f985360b550>},\n",
              " 'reddit': {'train': <torch.utils.data.dataloader.DataLoader at 0x7f985360b3a0>,\n",
              "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f985360b370>,\n",
              "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f985360ba90>},\n",
              " 'combined': {'train': <torch.utils.data.dataloader.DataLoader at 0x7f985360bbe0>,\n",
              "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f985360b0d0>,\n",
              "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f985360b970>}}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from torch.utils.data import BatchSampler, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "def get_dataloaders(datasets, train_batch_size, eval_batch_size):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        This function implements batch training by creating dataloaders for datasets to acclerate training.\n",
        "    Inputs:\n",
        "        - datasets (Dict[str, Dict]): a dictionary containing a mapping between dataset names and dataset values. \n",
        "        - train_batch_size (int): an integer which is used as the batch size when creating the train dataloader\n",
        "        - eval_batch_size (int): an integer which is used as the batch size when creating the validation and test dataloader\n",
        "    \"\"\"\n",
        "    # Retrieve the dataset split labels (\"train\", \"validation\", \"test\")\n",
        "    splits = datasets.keys()\n",
        "\n",
        "    # Choose different parameters for each dataset split\n",
        "    sampler_classes = {split: \n",
        "                       (RandomSampler if split == \"train\" else SequentialSampler) \n",
        "                       for split in splits}\n",
        "\n",
        "    batch_sizes = {split: \n",
        "                   (train_batch_size if split == \"train\" else eval_batch_size) \n",
        "                   for split in splits}\n",
        "\n",
        "    # Initialize the BatchSamplers with the differentiated parameters\n",
        "    batch_samplers = {split: \n",
        "                      BatchSampler(sampler_classes[split](datasets[split]),\n",
        "                                   batch_sizes[split],\n",
        "                                   drop_last=False)\n",
        "                      for split in splits}\n",
        "\n",
        "    # Build the dataloaders from the initialized BatchSamplers and the custom collate_fn\n",
        "    dataloaders = {split: \n",
        "                   DataLoader(datasets[split], \n",
        "                              batch_sampler=batch_samplers[split],\n",
        "                              collate_fn=datasets[split].collate_fn)\n",
        "                   for split in splits}\n",
        "\n",
        "    return dataloaders\n",
        "\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 16\n",
        "\n",
        "dataloaders = {key: get_dataloaders(ia_datasets[key], train_batch_size=TRAIN_BATCH_SIZE, eval_batch_size=EVAL_BATCH_SIZE) \n",
        "               for key in ia_datasets}\n",
        "dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcE3nPt_REtM"
      },
      "source": [
        "Check to ensure that lengths of dataset are as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En9tAuxiM3rJ",
        "outputId": "69a7cc61-4e63-4547-f66e-788da9c8a926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet's train length is 475.\n",
            "tweet's test length is 60.\n",
            "tweet's valid length is 60.\n",
            "tweet is good.\n",
            "\n",
            "reddit's train length is 90.\n",
            "reddit's test length is 12.\n",
            "reddit's valid length is 12.\n",
            "reddit is good.\n",
            "\n",
            "combined's train length is 565.\n",
            "combined's test length is 71.\n",
            "combined's valid length is 71.\n",
            "combined is good.\n",
            "\n",
            "All good - sizes are as expected!\n"
          ]
        }
      ],
      "source": [
        "import math \n",
        "\n",
        "def check_size(dataType, partitionType):\n",
        "  if partitionType == TRAIN: batchSize = TRAIN_BATCH_SIZE\n",
        "  else: batchSize = EVAL_BATCH_SIZE\n",
        "\n",
        "  got = len(dataloaders[dataType][partitionType])\n",
        "  expected = math.ceil(len(ia_datasets[dataType][partitionType].tokenized)/batchSize)\n",
        "  assert got == expected, f'Got {got}, expected {expected}'\n",
        "\n",
        "  print (f'{dataType}\\'s {partitionType} length is {expected}.')\n",
        "\n",
        "for d in [TWEET, REDDIT, COMBINED]:\n",
        "  for p in [TRAIN, TEST, 'valid']:\n",
        "    check_size(d, p)\n",
        "  print (f'{d} is good.\\n')\n",
        "    \n",
        "print ('All good - sizes are as expected!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0rmOLQcDI7C"
      },
      "source": [
        "## RoBERTa Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-tiBzI6yFW4",
        "outputId": "29fe6dc4-530e-4f38-d359-9123978e1706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaConfig {\n",
              "  \"_name_or_path\": \"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
              "  \"architectures\": [\n",
              "    \"XLMRobertaForSequenceClassification\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"negative\",\n",
              "    \"1\": \"neutral\",\n",
              "    \"2\": \"positive\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"negative\": 0,\n",
              "    \"neutral\": 1,\n",
              "    \"positive\": 2\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"xlm-roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.24.0\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250002\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "# set up the configuration for BERT model\n",
        "config = AutoConfig.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzuGjubyVt-4"
      },
      "source": [
        "#### RobERTa Regressor - Old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BusOzkczhcTo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel, XLMRobertaPreTrainedModel\n",
        "\n",
        "class XLMRobertaRegressor(XLMRobertaPreTrainedModel):\n",
        "    \n",
        "    def __init__(self, config, pretrained_model_name_or_path, ignore_index, drop_rate=0.2, freeze_roberta=False):\n",
        "      super().__init__(config)\n",
        "\n",
        "      self.hidden_size = config.hidden_size\n",
        "\n",
        "      self.n_classes = 1\n",
        "\n",
        "      self.xlmroberta = XLMRobertaModel.from_pretrained(pretrained_model_name_or_path)\n",
        "\n",
        "      self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(self.hidden_size, self.n_classes))\n",
        "        \n",
        "      self.loss_fct = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    def forward(self, input_ids, labels, attention_masks):\n",
        "        \n",
        "        outputs = self.xlmroberta(input_ids, attention_masks)\n",
        "        sequence_output = outputs[0]\n",
        "        \n",
        "        logits = self.regressor(sequence_output)\n",
        "\n",
        "        loss = self.loss_fct(logits.view(-1), labels.view(-1))\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SjaINdDkp6nG"
      },
      "outputs": [],
      "source": [
        "# (Aisha) Commented out to make the notebook run quicker.\n",
        "\n",
        "# model = XLMRobertaRegressor(config, PRETRAINED_MODEL_NAME, IGNORE_INDEX, drop_rate=0.2)\n",
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-bXQPBBVyEH"
      },
      "source": [
        "#### RobERTa Regressor - New"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FmHWfNOV1iv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c6126df9665f4cd7ad34dec8308bf7b5",
            "c7d69e1b46634fc4acf5589db8f4a08c",
            "b6303c66754c46d296715bcae230ee2e",
            "31985a713b5d416482e8fa8c783522ee",
            "7853b5a33d964f35850bef7c4d71256f",
            "038d5c5cc74b41fb9cec405761f61bef",
            "68fa5b9094de434282b1ba4d69d24490",
            "025b1cc0ac394a22ad9892400231725a",
            "069436089d5b4ed081d270cca23897f7",
            "74d8a8b3e50b4ede8bd4df89343ad8fa",
            "ba135a8aa51d4aa8ae4b039524c46658"
          ]
        },
        "outputId": "27e390c8-b717-4664-fc91-af39ad929f89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6126df9665f4cd7ad34dec8308bf7b5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel, XLMRobertaPreTrainedModel\n",
        "\n",
        "class XLMRobertaRegressor(nn.Module):\n",
        "    \n",
        "    def __init__(self, pretrained_model_name_or_path, drop_rate=0.2, freeze_camembert=False):\n",
        "      # super().__init__(config)\n",
        "\n",
        "      # self.hidden_size = config.hidden_size\n",
        "\n",
        "      # self.n_classes = 1\n",
        "\n",
        "      # self.xlmroberta = XLMRobertaModel.from_pretrained(pretrained_model_name_or_path)\n",
        "\n",
        "      # self.regressor = nn.Sequential(\n",
        "      #       nn.Dropout(drop_rate),\n",
        "      #       nn.Linear(self.hidden_size, self.n_classes))\n",
        "        \n",
        "      # self.loss_fct = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "        super(XLMRobertaRegressor, self).__init__()\n",
        "        D_in, D_out = 768, 1\n",
        "        \n",
        "        self.xlmroberta = XLMRobertaModel.from_pretrained(pretrained_model_name_or_path)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(D_in, D_out))\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        # outputs = self.xlmroberta(input_ids, attention_masks)\n",
        "        # sequence_output = outputs[0]\n",
        "        \n",
        "        # logits = self.regressor(sequence_output)\n",
        "\n",
        "        # loss = self.loss_fct(logits.view(-1), labels.view(-1))\n",
        "        # return loss, logits\n",
        "\n",
        "        outputs = self.xlmroberta(input_ids, attention_masks)\n",
        "        class_label_output = outputs[1]\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "\n",
        "model = XLMRobertaRegressor(PRETRAINED_MODEL_NAME, drop_rate=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLSbvhNJe7xg"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75IywPoWi9F3"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzT7utCFi_1v"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=5e-5,\n",
        "                  eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TePYzTAAjBPg"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 5\n",
        "total_steps = len(dataloaders[TWEET][TRAIN]) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
        "                 num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "loss_function = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "_QPeFT3JX75f",
        "outputId": "577b91ba-9715-466e-c4fb-4a1a9d60bf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/475 [00:00<?, ?it/s]<ipython-input-48-892fc1287448>:30: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(model.parameters(), clip_value)\n",
            "  0%|          | 1/475 [00:48<6:26:06, 48.87s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-892fc1287448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# for datasetType in [TWEET, REDDIT, COMBINED]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# print (f'Training on {datasetType}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m model = train(model, optimizer, scheduler, loss_function, epochs, \n\u001b[0m\u001b[1;32m     41\u001b[0m               dataloaders[TWEET][TRAIN], DEVICE, clip_value=2)\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-892fc1287448>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[1;32m     27\u001b[0m                              batch_labels.squeeze())\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
        "          train_dataloader, device, clip_value=2):\n",
        "  \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch #{epoch}')\n",
        "\n",
        "        best_loss = 1e10\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(tqdm(train_dataloader)): \n",
        "\n",
        "            batch_inputs, batch_masks, batch_labels = \\\n",
        "                               tuple(batch[field].to(device) for field in batch)\n",
        "\n",
        "\n",
        "            model.zero_grad()\n",
        "            outputs = model(batch_inputs, batch_masks)           \n",
        "            \n",
        "            outputs = outputs.to(torch.float64)\n",
        "            batch_masks = batch_masks.to(torch.float64)\n",
        "\n",
        "            loss = loss_function(outputs.squeeze(), \n",
        "                             batch_labels.squeeze())\n",
        "\n",
        "            loss.backward()\n",
        "            clip_grad_norm(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "                \n",
        "    return model\n",
        "\n",
        "model_variants = {}\n",
        "\n",
        "# for datasetType in [TWEET, REDDIT, COMBINED]:\n",
        "# print (f'Training on {datasetType}')\n",
        "model = train(model, optimizer, scheduler, loss_function, epochs, \n",
        "              dataloaders[TWEET][TRAIN], DEVICE, clip_value=2)\n",
        "\n",
        "# model[datasetType] = model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (model_variants.keys())"
      ],
      "metadata": {
        "id": "kEvP8JNf0MgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbsQG-H9fN9X"
      },
      "outputs": [],
      "source": [
        "# # We will use `AdamW` optimizer for BERT.\n",
        "# from transformers import AdamW\n",
        "\n",
        "# def get_optimizer(model, learning_rate, epsilon):\n",
        "#     no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "#     optimizer_grouped_parameters = [\n",
        "#         {\n",
        "#             \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "#             \"weight_decay\": 0.01,\n",
        "#         },\n",
        "#         {\n",
        "#             \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
        "#             \"weight_decay\": 0.0\n",
        "#         },\n",
        "#     ]\n",
        "\n",
        "#     optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=epsilon)\n",
        "\n",
        "#     return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srRkqr5nBk2L"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_preds, all_truth = [], []\n",
        "    for step, batch in enumerate(tqdm(dataloader)):\n",
        "        for field in batch:\n",
        "            batch[field] = batch[field].to(device)\n",
        "\n",
        "        _, preds = model(**batch)\n",
        "\n",
        "        for i in range(len(preds)):\n",
        "            preds_i = preds[i]\n",
        "            truth_i = batch['labels'][i].data.detach().cpu().tolist()\n",
        "\n",
        "            all_preds.append([p for p in preds_i])\n",
        "            all_truth.append([t for t in truth_i])\n",
        "    \n",
        "    return all_preds, all_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyk-CJfvBk2J"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "\n",
        "# from tqdm.auto import tqdm\n",
        "\n",
        "# def train(model, train_dataloader, optimizer, num_epochs=10, print_every=1, device='cpu'):\n",
        "#     model.to(device)\n",
        "\n",
        "#     model.train()\n",
        "\n",
        "#     for epoch_i in tqdm(range(num_epochs)):\n",
        "#         epoch_loss = 0\n",
        "\n",
        "#         for step, batch in enumerate(train_dataloader):\n",
        "#             for field in batch:\n",
        "#                 batch[field] = batch[field].to(device)\n",
        "\n",
        "#             loss, _ = model(**batch)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             epoch_loss += loss.sum().item()\n",
        "\n",
        "#         if (epoch_i + 1) % print_every == 0:\n",
        "#             print(f\"**** Epoch {epoch_i+1:03d} - Loss: {epoch_loss:.6f} ****\")\n",
        "    \n",
        "#     return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeWs14NTCxgB"
      },
      "source": [
        "## Fine tuning\n",
        "\n",
        "In the report (Liu et al., 2019)\n",
        "\n",
        "Parameters \n",
        "batch size as 128 and learning rate as 0.0001 w/ max length set to 50\n",
        "Adam (Kingma and Ba, 2014) used for optimization.\n",
        "All the other hyperparameters and the model size are the same as the default roberta-base model\n",
        "\n",
        "Training\n",
        "trained model for 30 epochs selecting model with lowest MSE on validation set\n",
        "fine-tuning process: followed all default settings recommended by Hugging Face.\n",
        "\n",
        "tunning learning rate: \n",
        "0.0001 and 0.00001 both achieved good scores regarding MSE and Pearson r."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5jT3UfZM8Q0"
      },
      "source": [
        "**Note:** here is where you can adjust the parameters for `learning_rate` and `num_epochs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wYNGpE2LwKb"
      },
      "outputs": [],
      "source": [
        "# define the optimizer for training\n",
        "# optimizer = get_optimizer(model, learning_rate=1e-03, epsilon=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU4IaOL2M7OH"
      },
      "outputs": [],
      "source": [
        "# start training\n",
        "# model_variants = {}\n",
        "\n",
        "# for name in dataloaders:\n",
        "#   model_variants[name] = train(model, dataloaders[name][TRAIN], optimizer, num_epochs=6, print_every=1, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjyzHadGNd9p"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "for name in dataloaders:\n",
        "  valid_preds, valid_truth = evaluate(model_variants[name], dataloaders[name]['validation'], device=DEVICE)\n",
        "  print(f\"Classification Report for %s model:\", name)\n",
        "  print(classification_report(valid_truth, valid_preds, digits=5, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lXxIfXLNsQd"
      },
      "source": [
        "Finally, score the model on the test dataset after making informed choices of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKb9nIL4Bk2R"
      },
      "outputs": [],
      "source": [
        "for name in dataloaders:\n",
        "  test_preds, test_truth = evaluate(model_variants[name], dataloaders[name]['test'], device=DEVICE)\n",
        "  print(classification_report(test_truth, test_preds, digits=5, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNEjy1UDgrcW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQKXVas1LzW_"
      },
      "source": [
        "## Base Line\n",
        "\n",
        "From 11/03's class during project proposal feedback\n",
        "\n",
        "## State of the Art\n",
        "From 11/03's class during project proposal feedback\n",
        "\n",
        "State of the art model should be regarded as XLM-T mode : Multilingual RoBERTa model trained over 200M tweets. Although this model in particular perfromed poorly on languages; Chinese, Hindi, Dutch, Korean,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqKG6JMyXNg"
      },
      "source": [
        "## Saving the model\n",
        "\n",
        "(Aisha) - Adding this here in case training takes a long time and we can give the model weights to the professor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlMfxFjmzFfo"
      },
      "outputs": [],
      "source": [
        "torch.save(model)\n",
        "print ('Model saved')\n",
        "\n",
        "tokenizer.save_vocabulary('./')\n",
        "print ('Tokenizer saved')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T59PctT1Pk9"
      },
      "source": [
        "## Experiment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djjtifb61X6h"
      },
      "source": [
        "Baseline models to test:\n",
        "1. BERT (Devlin et al., 2018): multilingual\n",
        "BERT model.\n",
        "2. XLM-R (Conneau et al., 2019): multilingual\n",
        "RoBERTa model.\n",
        "3. XLM-T (Barbieri et al., 2021): Multilingual\n",
        "RoBERTa model trained over 200M tweets.\n",
        "4. DistillBERT (Sanh et al., 2019): Multilingual\n",
        "distilled BERT model.\n",
        "5. MiniLM (Wang et al., 2020): Multilingual\n",
        "MiniLM model.\n",
        "\n",
        "(Liu et al., 2019) found that XLM-T achieved the best performance over 7 languages, suggesting that domain specific language model training is beneficial for our tweet intimacy analysis task\n",
        "(Liu et al., 2019) found that for zero-shot tasks, models has varying performances for different languages: The zero-shot performance is generally lower compared with the tasks with in-domain training. This suggests that the zero-shot task is challenging. We should explore different strategies to improve the zero-shot intimacy prediction performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae_m0cIqg2Jp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfrB2okCjYVn"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! pip install seqeval\n",
        "! pip install bertviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KXdAzrI1XVN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Set up device. Recommend to use GPU to accelerate training\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlP_zziGj1lG"
      },
      "outputs": [],
      "source": [
        "# specify which pre-trained BERT model to use\n",
        "PRETRAINED_MODEL_NAME_OR_PATH = 'bert-base-cased'\n",
        "\n",
        "# specify the value of `ignore_index`\n",
        "IGNORE_INDEX = -100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKG3tBvaj25K"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmHosmNwkvQt"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODRgIpruC2cF"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Notes from 11/15's class Bias in NLP - \n",
        "- Are there are biases in this model?\n",
        "- Are there subsets of human factors which we may encounter in these datasets that may contribute to biases?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUwDRyhuC4I7"
      },
      "source": [
        "## References"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kpHFYYTKKuLP",
        "Opsn06XGc9z5",
        "mv0p2FnOS2XK",
        "C18zWc2ytm1y",
        "psgQJz7bdFGB",
        "KzuGjubyVt-4"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d3c31c9f8014562b676e7c34beca0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da1cf1da675f423dad53ba11498fcc32",
              "IPY_MODEL_db80e30bafbc440f8da11f77aac83e49",
              "IPY_MODEL_039fe685a0df42329212f8760eeeefa1"
            ],
            "layout": "IPY_MODEL_9760c8d4f82a49ccad745e175979be03"
          }
        },
        "da1cf1da675f423dad53ba11498fcc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d51f91a9c04663a8f88bb17ffaf8ba",
            "placeholder": "​",
            "style": "IPY_MODEL_5ba1f18634bd4f49bf697edbb342f076",
            "value": "Downloading: 100%"
          }
        },
        "db80e30bafbc440f8da11f77aac83e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1da948ec124e6b84904d9ad9b6f5ab",
            "max": 841,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16ef0eaa75db4713a0f89b2e5432bf01",
            "value": 841
          }
        },
        "039fe685a0df42329212f8760eeeefa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de58883396f14d13a5c64c7f8e84c507",
            "placeholder": "​",
            "style": "IPY_MODEL_15acb395715b496cab8f5176dfeb82d4",
            "value": " 841/841 [00:00&lt;00:00, 31.7kB/s]"
          }
        },
        "9760c8d4f82a49ccad745e175979be03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d51f91a9c04663a8f88bb17ffaf8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba1f18634bd4f49bf697edbb342f076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1da948ec124e6b84904d9ad9b6f5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ef0eaa75db4713a0f89b2e5432bf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de58883396f14d13a5c64c7f8e84c507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15acb395715b496cab8f5176dfeb82d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2e0c3ba4bd3496c8e4decb8c18407cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebe47b4f2bf4438fb45da13a8df4d0ff",
              "IPY_MODEL_f53faea6f2ec45029ad932611a186493",
              "IPY_MODEL_4424baea97324ee59fb3e0dbf40d3926"
            ],
            "layout": "IPY_MODEL_8aa67ed2f61b4fc2816f77f11ba00d72"
          }
        },
        "ebe47b4f2bf4438fb45da13a8df4d0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87dee169afd45f79632468bc2c16b62",
            "placeholder": "​",
            "style": "IPY_MODEL_e17173aad7b643fa8ece2476beb5214e",
            "value": "Downloading: 100%"
          }
        },
        "f53faea6f2ec45029ad932611a186493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ca877f45c140918b0e72ec43248898",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c83c07755e64dcfa35da38c9ee0caab",
            "value": 5069051
          }
        },
        "4424baea97324ee59fb3e0dbf40d3926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd3cbd5a83749b2bd444a822879e466",
            "placeholder": "​",
            "style": "IPY_MODEL_c9116ad54d84406fa10a16ca9086704a",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 3.13MB/s]"
          }
        },
        "8aa67ed2f61b4fc2816f77f11ba00d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87dee169afd45f79632468bc2c16b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17173aad7b643fa8ece2476beb5214e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ca877f45c140918b0e72ec43248898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c83c07755e64dcfa35da38c9ee0caab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bd3cbd5a83749b2bd444a822879e466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9116ad54d84406fa10a16ca9086704a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57aa4cd09b1c45b1827612a3f92b1716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a7317833504444298d2d2be746d1855",
              "IPY_MODEL_cdcc8425ced5466d87242f400998dfd9",
              "IPY_MODEL_86145b497b2a4f16b717f9f83797a9b6"
            ],
            "layout": "IPY_MODEL_53d7bdf52bd64682811b42ad048b728f"
          }
        },
        "4a7317833504444298d2d2be746d1855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ec39f35ee248f8b37166ef9766aab5",
            "placeholder": "​",
            "style": "IPY_MODEL_fdb08d4f8c414dc7b6d460f48669c246",
            "value": "Downloading: 100%"
          }
        },
        "cdcc8425ced5466d87242f400998dfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee744dc5725493e98ee92ed1e8474a1",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d3855b90074cf78ae20397620da34e",
            "value": 150
          }
        },
        "86145b497b2a4f16b717f9f83797a9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8f21d425e274ddeb635e144df3fddea",
            "placeholder": "​",
            "style": "IPY_MODEL_161c6f477813474a8e2c1a71c3d709b7",
            "value": " 150/150 [00:00&lt;00:00, 3.31kB/s]"
          }
        },
        "53d7bdf52bd64682811b42ad048b728f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ec39f35ee248f8b37166ef9766aab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb08d4f8c414dc7b6d460f48669c246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ee744dc5725493e98ee92ed1e8474a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d3855b90074cf78ae20397620da34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8f21d425e274ddeb635e144df3fddea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161c6f477813474a8e2c1a71c3d709b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6126df9665f4cd7ad34dec8308bf7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7d69e1b46634fc4acf5589db8f4a08c",
              "IPY_MODEL_b6303c66754c46d296715bcae230ee2e",
              "IPY_MODEL_31985a713b5d416482e8fa8c783522ee"
            ],
            "layout": "IPY_MODEL_7853b5a33d964f35850bef7c4d71256f"
          }
        },
        "c7d69e1b46634fc4acf5589db8f4a08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_038d5c5cc74b41fb9cec405761f61bef",
            "placeholder": "​",
            "style": "IPY_MODEL_68fa5b9094de434282b1ba4d69d24490",
            "value": "Downloading:  16%"
          }
        },
        "b6303c66754c46d296715bcae230ee2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_025b1cc0ac394a22ad9892400231725a",
            "max": 1112271561,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_069436089d5b4ed081d270cca23897f7",
            "value": 181714944
          }
        },
        "31985a713b5d416482e8fa8c783522ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d8a8b3e50b4ede8bd4df89343ad8fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ba135a8aa51d4aa8ae4b039524c46658",
            "value": " 182M/1.11G [00:02&lt;00:12, 77.2MB/s]"
          }
        },
        "7853b5a33d964f35850bef7c4d71256f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038d5c5cc74b41fb9cec405761f61bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68fa5b9094de434282b1ba4d69d24490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "025b1cc0ac394a22ad9892400231725a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069436089d5b4ed081d270cca23897f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d8a8b3e50b4ede8bd4df89343ad8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba135a8aa51d4aa8ae4b039524c46658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}